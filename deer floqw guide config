# ğŸ¦Œ DeerFlow

[![Python 3.12+](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![DeepWiki](https://img.shields.io/badge/DeepWiki-bytedance%2Fdeer--flow-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McCcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/bytedance/deer-flow)

<!-- DeepWiki badge generated by https://deepwiki.ryoppippi.com/ -->

[English](./README.md) | [ç®€ä½“ä¸­æ–‡](./README_zh.md) | [æ—¥æœ¬èª](./README_ja.md) | [Deutsch](./README_de.md) | [EspaÃ±ol](./README_es.md) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](./README_ru.md) | [Portuguese](./README_pt.md)

> Originated from Open Source, give back to Open Source.

**DeerFlow** (**D**eep **E**xploration and **E**fficient **R**esearch **Flow**) is a community-driven Deep Research framework that builds upon the incredible work of the open source community. Our goal is to combine language models with specialized tools for tasks like web search, crawling, and Python code execution, while giving back to the community that made this possible.

Currently, DeerFlow has officially entered the [FaaS Application Center of Volcengine](https://console.volcengine.com/vefaas/region:vefaas+cn-beijing/market). Users can experience it online through the [experience link](https://console.volcengine.com/vefaas/region:vefaas+cn-beijing/market/deerflow/?channel=github&source=deerflow) to intuitively feel its powerful functions and convenient operations. At the same time, to meet the deployment needs of different users, DeerFlow supports one-click deployment based on Volcengine. Click the [deployment link](https://console.volcengine.com/vefaas/region:vefaas+cn-beijing/application/create?templateId=683adf9e372daa0008aaed5c&channel=github&source=deerflow) to quickly complete the deployment process and start an efficient research journey.


Please visit [our official website](https://deerflow.tech/) for more details.

## Demo

### Video

<https://github.com/user-attachments/assets/f3786598-1f2a-4d07-919e-8b99dfa1de3e>

In this demo, we showcase how to use DeerFlow to:

- Seamlessly integrate with MCP services
- Conduct the Deep Research process and produce a comprehensive report with images
- Create podcast audio based on the generated report

### Replays

- [How tall is Eiffel Tower compared to tallest building?](https://deerflow.tech/chat?replay=eiffel-tower-vs-tallest-building)
- [What are the top trending repositories on GitHub?](https://deerflow.tech/chat?replay=github-top-trending-repo)
- [Write an article about Nanjing's traditional dishes](https://deerflow.tech/chat?replay=nanjing-traditional-dishes)
- [How to decorate a rental apartment?](https://deerflow.tech/chat?replay=rental-apartment-decoration)
- [Visit our official website to explore more replays.](https://deerflow.tech/#case-studies)

---

## ğŸ“‘ Table of Contents

- [ğŸš€ Quick Start](#quick-start)
- [ğŸŒŸ Features](#features)
- [ğŸ—ï¸ Architecture](#architecture)
- [ğŸ› ï¸ Development](#development)
- [ğŸ³ Docker](#docker)
- [ğŸ—£ï¸ Text-to-Speech Integration](#text-to-speech-integration)
- [ğŸ“š Examples](#examples)
- [â“ FAQ](#faq)
- [ğŸ“œ License](#license)
- [ğŸ’– Acknowledgments](#acknowledgments)
- [â­ Star History](#star-history)

## Quick Start

DeerFlow is developed in Python, and comes with a web UI written in Node.js. To ensure a smooth setup process, we recommend using the following tools:

### Recommended Tools

- **[`uv`](https://docs.astral.sh/uv/getting-started/installation/):**
  Simplify Python environment and dependency management. `uv` automatically creates a virtual environment in the root directory and installs all required packages for youâ€”no need to manually install Python environments.

- **[`nvm`](https://github.com/nvm-sh/nvm):**
  Manage multiple versions of the Node.js runtime effortlessly.

- **[`pnpm`](https://pnpm.io/installation):**
  Install and manage dependencies of Node.js project.

### Environment Requirements

Make sure your system meets the following minimum requirements:

- **[Python](https://www.python.org/downloads/):** Version `3.12+`
- **[Node.js](https://nodejs.org/en/download/):** Version `22+`

### Installation

```bash
# Clone the repository
git clone https://github.com/bytedance/deer-flow.git
cd deer-flow

# Install dependencies, uv will take care of the python interpreter and venv creation, and install the required packages
uv sync

# Configure .env with your API keys
# Tavily: https://app.tavily.com/home
# Brave_SEARCH: https://brave.com/search/api/
# volcengine TTS: Add your TTS credentials if you have them
cp .env.example .env

# See the 'Supported Search Engines' and 'Text-to-Speech Integration' sections below for all available options

# Configure conf.yaml for your LLM model and API keys
# Please refer to 'docs/configuration_guide.md' for more details
cp conf.yaml.example conf.yaml

# Install marp for ppt generation
# https://github.com/marp-team/marp-cli?tab=readme-ov-file#use-package-manager
brew install marp-cli
```

Optionally, install web UI dependencies via [pnpm](https://pnpm.io/installation):

```bash
cd deer-flow/web
pnpm install
```

### Configurations

Please refer to the [Configuration Guide](docs/configuration_guide.md) for more details.

> [!NOTE]
> Before you start the project, read the guide carefully, and update the configurations to match your specific settings and requirements.

### Console UI

The quickest way to run the project is to use the console UI.

```bash
# Run the project in a bash-like shell
uv run main.py
```

### Web UI

This project also includes a Web UI, offering a more dynamic and engaging interactive experience.

> [!NOTE]
> You need to install the dependencies of web UI first.

```bash
# Run both the backend and frontend servers in development mode
# On macOS/Linux
./bootstrap.sh -d

# On Windows
bootstrap.bat -d
```

Open your browser and visit [`http://localhost:3000`](http://localhost:3000) to explore the web UI.

Explore more details in the [`web`](./web/) directory.

## Supported Search Engines

### Web Search

DeerFlow supports multiple search engines that can be configured in your `.env` file using the `SEARCH_API` variable:

- **Tavily** (default): A specialized search API for AI applications
  - Requires `TAVILY_API_KEY` in your `.env` file
  - Sign up at: https://app.tavily.com/home

- **DuckDuckGo**: Privacy-focused search engine
  - No API key required

- **Brave Search**: Privacy-focused search engine with advanced features
  - Requires `BRAVE_SEARCH_API_KEY` in your `.env` file
  - Sign up at: https://brave.com/search/api/

- **Arxiv**: Scientific paper search for academic research
  - No API key required
  - Specialized for scientific and academic papers

To configure your preferred search engine, set the `SEARCH_API` variable in your `.env` file:

```bash
# Choose one: tavily, duckduckgo, brave_search, arxiv
SEARCH_API=tavily
```

### Private Knowledgebase

DeerFlow support private knowledgebase such as ragflow and vikingdb, so that you can use your private documents to answer questions.

- **[RAGFlow](https://ragflow.io/docs/dev/)**ï¼šopen source RAG engine
   ```
   # examples in .env.example
   RAG_PROVIDER=ragflow
   RAGFLOW_API_URL="http://localhost:9388"
   RAGFLOW_API_KEY="ragflow-xxx"
   RAGFLOW_RETRIEVAL_SIZE=10
   RAGFLOW_CROSS_LANGUAGES=English,Chinese,Spanish,French,German,Japanese,Korean
   ```

## Features

### Core Capabilities

- ğŸ¤– **LLM Integration**
  - It supports the integration of most models through [litellm](https://docs.litellm.ai/docs/providers).
  - Support for open source models like Qwen
  - OpenAI-compatible API interface
  - Multi-tier LLM system for different task complexities

### Tools and MCP Integrations

- ğŸ” **Search and Retrieval**
  - Web search via Tavily, Brave Search and more
  - Crawling with Jina
  - Advanced content extraction
  - Support for private knowledgebase

- ğŸ“ƒ **RAG Integration**

  - Supports mentioning files from [RAGFlow](https://github.com/infiniflow/ragflow) within the input box. [Start up RAGFlow server](https://ragflow.io/docs/dev/).

- ğŸ”— **MCP Seamless Integration**
  - Expand capabilities for private domain access, knowledge graph, web browsing and more
  - Facilitates integration of diverse research tools and methodologies

### Human Collaboration

- ğŸ§  **Human-in-the-loop**
  - Supports interactive modification of research plans using natural language
  - Supports auto-acceptance of research plans

- ğŸ“ **Report Post-Editing**
  - Supports Notion-like block editing
  - Allows AI refinements, including AI-assisted polishing, sentence shortening, and expansion
  - Powered by [tiptap](https://tiptap.dev/)

### Content Creation

- ğŸ™ï¸ **Podcast and Presentation Generation**
  - AI-powered podcast script generation and audio synthesis
  - Automated creation of simple PowerPoint presentations
  - Customizable templates for tailored content

## Architecture

DeerFlow implements a modular multi-agent system architecture designed for automated research and code analysis. The system is built on LangGraph, enabling a flexible state-based workflow where components communicate through a well-defined message passing system.

![Architecture Diagram](./assets/architecture.png)

> See it live at [deerflow.tech](https://deerflow.tech/#multi-agent-architecture)

The system employs a streamlined workflow with the following components:

1. **Coordinator**: The entry point that manages the workflow lifecycle

   - Initiates the research process based on user input
   - Delegates tasks to the planner when appropriate
   - Acts as the primary interface between the user and the system

2. **Planner**: Strategic component for task decomposition and planning

   - Analyzes research objectives and creates structured execution plans
   - Determines if enough context is available or if more research is needed
   - Manages the research flow and decides when to generate the final report

3. **Research Team**: A collection of specialized agents that execute the plan:

   - **Researcher**: Conducts web searches and information gathering using tools like web search engines, crawling and even MCP services.
   - **Coder**: Handles code analysis, execution, and technical tasks using Python REPL tool.
     Each agent has access to specific tools optimized for their role and operates within the LangGraph framework

4. **Reporter**: Final stage processor for research outputs
   - Aggregates findings from the research team
   - Processes and structures the collected information
   - Generates comprehensive research reports

## Text-to-Speech Integration

DeerFlow now includes a Text-to-Speech (TTS) feature that allows you to convert research reports to speech. This feature uses the volcengine TTS API to generate high-quality audio from text. Features like speed, volume, and pitch are also customizable.

### Using the TTS API

You can access the TTS functionality through the `/api/tts` endpoint:

```bash
# Example API call using curl
curl --location 'http://localhost:8000/api/tts' \
--header 'Content-Type: application/json' \
--data '{
    "text": "This is a test of the text-to-speech functionality.",
    "speed_ratio": 1.0,
    "volume_ratio": 1.0,
    "pitch_ratio": 1.0
}' \
--output speech.mp3
```

## Development

### Testing

Run the test suite:

```bash
# Run all tests
make test

# Run specific test file
pytest tests/integration/test_workflow.py

# Run with coverage
make coverage
```

### Code Quality

```bash
# Run linting
make lint

# Format code
make format
```

### Debugging with LangGraph Studio

DeerFlow uses LangGraph for its workflow architecture. You can use LangGraph Studio to debug and visualize the workflow in real-time.

#### Running LangGraph Studio Locally

DeerFlow includes a `langgraph.json` configuration file that defines the graph structure and dependencies for the LangGraph Studio. This file points to the workflow graphs defined in the project and automatically loads environment variables from the `.env` file.

##### Mac

```bash
# Install uv package manager if you don't have it
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies and start the LangGraph server
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.12 langgraph dev --allow-blocking
```

##### Windows / Linux

```bash
# Install dependencies
pip install -e .
pip install -U "langgraph-cli[inmem]"

# Start the LangGraph server
langgraph dev
```

After starting the LangGraph server, you'll see several URLs in the terminal:

- API: http://127.0.0.1:2024
- Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- API Docs: http://127.0.0.1:2024/docs

Open the Studio UI link in your browser to access the debugging interface.

#### Using LangGraph Studio

In the Studio UI, you can:

1. Visualize the workflow graph and see how components connect
2. Trace execution in real-time to see how data flows through the system
3. Inspect the state at each step of the workflow
4. Debug issues by examining inputs and outputs of each component
5. Provide feedback during the planning phase to refine research plans

When you submit a research topic in the Studio UI, you'll be able to see the entire workflow execution, including:

- The planning phase where the research plan is created
- The feedback loop where you can modify the plan
- The research and writing phases for each section
- The final report generation

### Enabling LangSmith Tracing

DeerFlow supports LangSmith tracing to help you debug and monitor your workflows. To enable LangSmith tracing:

1. Make sure your `.env` file has the following configurations (see `.env.example`):

   ```bash
   LANGSMITH_TRACING=true
   LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
   LANGSMITH_API_KEY="xxx"
   LANGSMITH_PROJECT="xxx"
   ```

2. Start tracing and visualize the graph locally with LangSmith by running:
   ```bash
   langgraph dev
   ```

This will enable trace visualization in LangGraph Studio and send your traces to LangSmith for monitoring and analysis.

## Docker

You can also run this project with Docker.

First, you need read the [configuration](docs/configuration_guide.md) below. Make sure `.env`, `.conf.yaml` files are ready.

Second, to build a Docker image of your own web server:

```bash
docker build -t deer-flow-api .
```

Final, start up a docker container running the web server:

```bash
# Replace deer-flow-api-app with your preferred container name
docker run -d -t -p 8000:8000 --env-file .env --name deer-flow-api-app deer-flow-api

# stop the server
docker stop deer-flow-api-app
```

### Docker Compose (include both backend and frontend)

DeerFlow provides a docker-compose setup to easily run both the backend and frontend together:

```bash
# building docker image
docker compose build

# start the server
docker compose up
```

## Examples

The following examples demonstrate the capabilities of DeerFlow:

### Research Reports

1. **OpenAI Sora Report** - Analysis of OpenAI's Sora AI tool

   - Discusses features, access, prompt engineering, limitations, and ethical considerations
   - [View full report](examples/openai_sora_report.md)

2. **Google's Agent to Agent Protocol Report** - Overview of Google's Agent to Agent (A2A) protocol

   - Discusses its role in AI agent communication and its relationship with Anthropic's Model Context Protocol (MCP)
   - [View full report](examples/what_is_agent_to_agent_protocol.md)

3. **What is MCP?** - A comprehensive analysis of the term "MCP" across multiple contexts

   - Explores Model Context Protocol in AI, Monocalcium Phosphate in chemistry, and Micro-channel Plate in electronics
   - [View full report](examples/what_is_mcp.md)

4. **Bitcoin Price Fluctuations** - Analysis of recent Bitcoin price movements

   - Examines market trends, regulatory influences, and technical indicators
   - Provides recommendations based on historical data
   - [View full report](examples/bitcoin_price_fluctuation.md)

5. **What is LLM?** - An in-depth exploration of Large Language Models

   - Discusses architecture, training, applications, and ethical considerations
   - [View full report](examples/what_is_llm.md)

6. **How to Use Claude for Deep Research?** - Best practices and workflows for using Claude in deep research

   - Covers prompt engineering, data analysis, and integration with other tools
   - [View full report](examples/how_to_use_claude_deep_research.md)

7. **AI Adoption in Healthcare: Influencing Factors** - Analysis of factors driving AI adoption in healthcare

   - Discusses AI technologies, data quality, ethical considerations, economic evaluations, organizational readiness, and digital infrastructure
   - [View full report](examples/AI_adoption_in_healthcare.md)

8. **Quantum Computing Impact on Cryptography** - Analysis of quantum computing's impact on cryptography

   - Discusses vulnerabilities of classical cryptography, post-quantum cryptography, and quantum-resistant cryptographic solutions
   - [View full report](examples/Quantum_Computing_Impact_on_Cryptography.md)

9. **Cristiano Ronaldo's Performance Highlights** - Analysis of Cristiano Ronaldo's performance highlights
   - Discusses his career achievements, international goals, and performance in various matches
   - [View full report](examples/Cristiano_Ronaldo's_Performance_Highlights.md)

To run these examples or create your own research reports, you can use the following commands:

```bash
# Run with a specific query
uv run main.py "What factors are influencing AI adoption in healthcare?"

# Run with custom planning parameters
uv run main.py --max_plan_iterations 3 "How does quantum computing impact cryptography?"

# Run in interactive mode with built-in questions
uv run main.py --interactive

# Or run with basic interactive prompt
uv run main.py

# View all available options
uv run main.py --help
```

### Interactive Mode

The application now supports an interactive mode with built-in questions in both English and Chinese:

1. Launch the interactive mode:

   ```bash
   uv run main.py --interactive
   ```

2. Select your preferred language (English or ä¸­æ–‡)

3. Choose from a list of built-in questions or select the option to ask your own question

4. The system will process your question and generate a comprehensive research report

### Human in the Loop

DeerFlow includes a human in the loop mechanism that allows you to review, edit, and approve research plans before they are executed:

1. **Plan Review**: When human in the loop is enabled, the system will present the generated research plan for your review before execution

2. **Providing Feedback**: You can:

   - Accept the plan by responding with `[ACCEPTED]`
   - Edit the plan by providing feedback (e.g., `[EDIT PLAN] Add more steps about technical implementation`)
   - The system will incorporate your feedback and generate a revised plan

3. **Auto-acceptance**: You can enable auto-acceptance to skip the review process:

   - Via API: Set `auto_accepted_plan: true` in your request

4. **API Integration**: When using the API, you can provide feedback through the `feedback` parameter:

   ```json
   {
     "messages": [{ "role": "user", "content": "What is quantum computing?" }],
     "thread_id": "my_thread_id",
     "auto_accepted_plan": false,
     "feedback": "[EDIT PLAN] Include more about quantum algorithms"
   }
   ```

### Command Line Arguments

The application supports several command-line arguments to customize its behavior:

- **query**: The research query to process (can be multiple words)
- **--interactive**: Run in interactive mode with built-in questions
- **--max_plan_iterations**: Maximum number of planning cycles (default: 1)
- **--max_step_num**: Maximum number of steps in a research plan (default: 3)
- **--debug**: Enable detailed debug logging

## FAQ

Please refer to the [FAQ.md](docs/FAQ.md) for more details.

## License

This project is open source and available under the [MIT License](./LICENSE).

## Acknowledgments

DeerFlow is built upon the incredible work of the open-source community. We are deeply grateful to all the projects and contributors whose efforts have made DeerFlow possible. Truly, we stand on the shoulders of giants.

We would like to extend our sincere appreciation to the following projects for their invaluable contributions:

- **[LangChain](https://github.com/langchain-ai/langchain)**: Their exceptional framework powers our LLM interactions and chains, enabling seamless integration and functionality.
- **[LangGraph](https://github.com/langchain-ai/langgraph)**: Their innovative approach to multi-agent orchestration has been instrumental in enabling DeerFlow's sophisticated workflows.
- **[Novel](https://github.com/steven-tey/novel)**: Their Notion-style WYSIWYG editor supports our report editing and AI-assisted rewriting.
- **[RAGFlow](https://github.com/infiniflow/ragflow)**: We have achieved support for research on users' private knowledge bases through integration with RAGFlow.

These projects exemplify the transformative power of open-source collaboration, and we are proud to build upon their foundations.

### Key Contributors

A heartfelt thank you goes out to the core authors of `DeerFlow`, whose vision, passion, and dedication have brought this project to life:

- **[Daniel Walnut](https://github.com/hetaoBackend/)**
- **[Henry Li](https://github.com/magiccube/)**

Your unwavering commitment and expertise have been the driving force behind DeerFlow's success. We are honored to have you at the helm of this journey.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=bytedance/deer-flow&type=Date)](https://star-history.com/#bytedance/deer-flow&Date)






# Configuration Guide

## Quick Settings

Copy the `conf.yaml.example` file to `conf.yaml` and modify the configurations to match your specific settings and requirements.

```bash
cd deer-flow
cp conf.yaml.example conf.yaml
```

## Which models does DeerFlow support?

In DeerFlow, we currently only support non-reasoning models. This means models like OpenAI's o1/o3 or DeepSeek's R1 are not supported yet, but we plan to add support for them in the future. Additionally, all Gemma-3 models are currently unsupported due to the lack of tool usage capabilities.

### Supported Models

`doubao-1.5-pro-32k-250115`, `gpt-4o`, `qwen-max-latest`, `gemini-2.0-flash`, `deepseek-v3`, and theoretically any other non-reasoning chat models that implement the OpenAI API specification.

> [!NOTE]
> The Deep Research process requires the model to have a **longer context window**, which is not supported by all models.
> A work-around is to set the `Max steps of a research plan` to `2` in the settings dialog located on the top right corner of the web page,
> or set `max_step_num` to `2` when invoking the API.

### How to switch models?
You can switch the model in use by modifying the `conf.yaml` file in the root directory of the project, using the configuration in the [litellm format](https://docs.litellm.ai/docs/providers/openai_compatible).

---

### How to use OpenAI-Compatible models?

DeerFlow supports integration with OpenAI-Compatible models, which are models that implement the OpenAI API specification. This includes various open-source and commercial models that provide API endpoints compatible with the OpenAI format. You can refer to [litellm OpenAI-Compatible](https://docs.litellm.ai/docs/providers/openai_compatible) for detailed documentation.
The following is a configuration example of `conf.yaml` for using OpenAI-Compatible models:

```yaml
# An example of Doubao models served by VolcEngine
BASIC_MODEL:
  base_url: "https://ark.cn-beijing.volces.com/api/v3"
  model: "doubao-1.5-pro-32k-250115"
  api_key: YOUR_API_KEY

# An example of Aliyun models
BASIC_MODEL:
  base_url: "https://dashscope.aliyuncs.com/compatible-mode/v1"
  model: "qwen-max-latest"
  api_key: YOUR_API_KEY

# An example of deepseek official models
BASIC_MODEL:
  base_url: "https://api.deepseek.com"
  model: "deepseek-chat"
  api_key: YOUR_API_KEY

# An example of Google Gemini models using OpenAI-Compatible interface
BASIC_MODEL:
  base_url: "https://generativelanguage.googleapis.com/v1beta/openai/"
  model: "gemini-2.0-flash"
  api_key: YOUR_API_KEY
```

### How to use models with self-signed SSL certificates?

If your LLM server uses self-signed SSL certificates, you can disable SSL certificate verification by adding the `verify_ssl: false` parameter to your model configuration:

```yaml
BASIC_MODEL:
  base_url: "https://your-llm-server.com/api/v1"
  model: "your-model-name"
  api_key: YOUR_API_KEY
  verify_ssl: false  # Disable SSL certificate verification for self-signed certificates
```

> [!WARNING]
> Disabling SSL certificate verification reduces security and should only be used in development environments or when you trust the LLM server. In production environments, it's recommended to use properly signed SSL certificates.

### How to use Ollama models?

DeerFlow supports the integration of Ollama models. You can refer to [litellm Ollama](https://docs.litellm.ai/docs/providers/ollama). <br>
The following is a configuration example of `conf.yaml` for using Ollama models(you might need to run the 'ollama serve' first):

```yaml
BASIC_MODEL:
  model: "model-name"  # Model name, which supports the completions API(important), such as: qwen3:8b, mistral-small3.1:24b, qwen2.5:3b
  base_url: "http://localhost:11434/v1" # Local service address of Ollama, which can be started/viewed via ollama serve
  api_key: "whatever"  # Mandatory, fake api_key with a random string you like :-)
```

### How to use OpenRouter models?

DeerFlow supports the integration of OpenRouter models. You can refer to [litellm OpenRouter](https://docs.litellm.ai/docs/providers/openrouter). To use OpenRouter models, you need to:
1. Obtain the OPENROUTER_API_KEY from OpenRouter (https://openrouter.ai/) and set it in the environment variable.
2. Add the `openrouter/` prefix before the model name.
3. Configure the correct OpenRouter base URL.

The following is a configuration example for using OpenRouter models:
1. Configure OPENROUTER_API_KEY in the environment variable (such as the `.env` file)
```ini
OPENROUTER_API_KEY=""
```
2. Set the model name in `conf.yaml`
```yaml
BASIC_MODEL:
  model: "openrouter/google/palm-2-chat-bison"
```

Note: The available models and their exact names may change over time. Please verify the currently available models and their correct identifiers in [OpenRouter's official documentation](https://openrouter.ai/docs).


### How to use Azure OpenAI chat models?

DeerFlow supports the integration of Azure OpenAI chat models. You can refer to [AzureChatOpenAI](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.azure.AzureChatOpenAI.html). Configuration example of `conf.yaml`:
```yaml
BASIC_MODEL:
  model: "azure/gpt-4o-2024-08-06"
  azure_endpoint: $AZURE_OPENAI_ENDPOINT
  api_version: $OPENAI_API_VERSION
  api_key: $AZURE_OPENAI_API_KEY
```

## About Search Engine

### How to control search domains for Tavily?

DeerFlow allows you to control which domains are included or excluded in Tavily search results through the configuration file. This helps improve search result quality and reduce hallucinations by focusing on trusted sources.

`Tips`: it only supports Tavily currently. 

You can configure domain filtering in your `conf.yaml` file as follows:

```yaml
SEARCH_ENGINE:
  engine: tavily
  # Only include results from these domains (whitelist)
  include_domains:
    - trusted-news.com
    - gov.org
    - reliable-source.edu
  # Exclude results from these domains (blacklist)
  exclude_domains:
    - unreliable-site.com
    - spam-domain.net


# æ€è€ƒå—äº¤äº’æµç¨‹æµ‹è¯•

## æµ‹è¯•åœºæ™¯

### åœºæ™¯ 1: å®Œæ•´çš„æ·±åº¦æ€è€ƒæµç¨‹

**æ­¥éª¤**:
1. å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼
2. å‘é€é—®é¢˜ï¼š"ä»€ä¹ˆæ˜¯ vibe codingï¼Ÿ"
3. è§‚å¯Ÿäº¤äº’æµç¨‹

**é¢„æœŸè¡Œä¸º**:

#### é˜¶æ®µ 1: æ·±åº¦æ€è€ƒå¼€å§‹
- âœ… æ€è€ƒå—ç«‹å³å‡ºç°å¹¶å±•å¼€
- âœ… ä½¿ç”¨è“è‰²ä¸»é¢˜ï¼ˆè¾¹æ¡†ã€èƒŒæ™¯ã€å›¾æ ‡ã€æ–‡å­—ï¼‰
- âœ… æ˜¾ç¤ºåŠ è½½åŠ¨ç”»
- âœ… ä¸æ˜¾ç¤ºè®¡åˆ’å¡ç‰‡
- âœ… æ¨ç†å†…å®¹å®æ—¶æµå¼æ›´æ–°

#### é˜¶æ®µ 2: æ€è€ƒè¿‡ç¨‹ä¸­
- âœ… æ€è€ƒå—ä¿æŒå±•å¼€çŠ¶æ€
- âœ… è“è‰²ä¸»é¢˜æŒç»­æ˜¾ç¤º
- âœ… æ¨ç†å†…å®¹æŒç»­å¢åŠ 
- âœ… åŠ è½½åŠ¨ç”»æŒç»­æ˜¾ç¤º
- âœ… è®¡åˆ’å¡ç‰‡ä»ç„¶ä¸æ˜¾ç¤º

#### é˜¶æ®µ 3: å¼€å§‹æ¥æ”¶è®¡åˆ’å†…å®¹
- âœ… æ€è€ƒå—è‡ªåŠ¨æŠ˜å 
- âœ… ä¸»é¢˜ä» primary åˆ‡æ¢ä¸ºé»˜è®¤
- âœ… åŠ è½½åŠ¨ç”»æ¶ˆå¤±
- âœ… è®¡åˆ’å¡ç‰‡ä»¥ä¼˜é›…åŠ¨ç”»å‡ºç°ï¼ˆopacity: 0â†’1, y: 20â†’0ï¼‰
- âœ… è®¡åˆ’å†…å®¹ä¿æŒæµå¼æ›´æ–°æ•ˆæœ

#### é˜¶æ®µ 4: è®¡åˆ’æµå¼è¾“å‡º
- âœ… æ ‡é¢˜é€æ­¥æ˜¾ç¤º
- âœ… æ€è·¯å†…å®¹æµå¼æ›´æ–°
- âœ… æ­¥éª¤åˆ—è¡¨é€é¡¹æ˜¾ç¤º
- âœ… æ¯ä¸ªæ­¥éª¤çš„æ ‡é¢˜å’Œæè¿°åˆ†åˆ«æµå¼æ¸²æŸ“

#### é˜¶æ®µ 5: è®¡åˆ’å®Œæˆ
- âœ… æ€è€ƒå—ä¿æŒæŠ˜å çŠ¶æ€
- âœ… è®¡åˆ’å¡ç‰‡å®Œå…¨æ˜¾ç¤º
- âœ… ç”¨æˆ·å¯æ‰‹åŠ¨å±•å¼€æ€è€ƒå—æŸ¥çœ‹æ¨ç†è¿‡ç¨‹

### åœºæ™¯ 2: æ‰‹åŠ¨äº¤äº’æµ‹è¯•

**æ­¥éª¤**:
1. åœ¨æ€è€ƒå®Œæˆåï¼Œæ‰‹åŠ¨ç‚¹å‡»æ€è€ƒå—
2. éªŒè¯å±•å¼€/æŠ˜å åŠŸèƒ½

**é¢„æœŸè¡Œä¸º**:
- âœ… ç‚¹å‡»å¯æ­£å¸¸å±•å¼€/æŠ˜å 
- âœ… åŠ¨ç”»æ•ˆæœæµç•…
- âœ… å†…å®¹å®Œæ•´æ˜¾ç¤º
- âœ… ä¸å½±å“è®¡åˆ’å¡ç‰‡æ˜¾ç¤º

### åœºæ™¯ 3: è¾¹ç•Œæƒ…å†µæµ‹è¯•

#### 3.1 åªæœ‰æ¨ç†å†…å®¹ï¼Œæ²¡æœ‰è®¡åˆ’å†…å®¹
**é¢„æœŸ**: æ€è€ƒå—ä¿æŒå±•å¼€ï¼Œä¸æ˜¾ç¤ºè®¡åˆ’å¡ç‰‡

#### 3.2 æ²¡æœ‰æ¨ç†å†…å®¹ï¼Œåªæœ‰è®¡åˆ’å†…å®¹
**é¢„æœŸ**: ä¸æ˜¾ç¤ºæ€è€ƒå—ï¼Œç›´æ¥æ˜¾ç¤ºè®¡åˆ’å¡ç‰‡

#### 3.3 æ¨ç†å†…å®¹ä¸ºç©º
**é¢„æœŸ**: ä¸æ˜¾ç¤ºæ€è€ƒå—ï¼Œç›´æ¥æ˜¾ç¤ºè®¡åˆ’å¡ç‰‡

## éªŒè¯è¦ç‚¹

### è§†è§‰æ•ˆæœ
- [ ] Primary ä¸»é¢˜è‰²åœ¨æ€è€ƒé˜¶æ®µæ­£ç¡®æ˜¾ç¤º
- [ ] ä¸»é¢˜åˆ‡æ¢åŠ¨ç”»æµç•…
- [ ] å­—ä½“æƒé‡ä¸ CardTitle ä¿æŒä¸€è‡´ (`font-semibold`)
- [ ] åœ†è§’è®¾è®¡ä¸å…¶ä»–å¡ç‰‡ç»Ÿä¸€ (`rounded-xl`)
- [ ] å›¾æ ‡å°ºå¯¸å’Œé¢œè‰²æ­£ç¡®å˜åŒ– (18px, primary/muted-foreground)
- [ ] å†…è¾¹è·ä¸è®¾è®¡ç³»ç»Ÿä¸€è‡´ (`px-6 py-4`)
- [ ] æ•´ä½“è§†è§‰å±‚æ¬¡ä¸é¡µé¢åè°ƒ

### äº¤äº’é€»è¾‘
- [ ] è‡ªåŠ¨å±•å¼€/æŠ˜å æ—¶æœºæ­£ç¡®
- [ ] æ‰‹åŠ¨å±•å¼€/æŠ˜å åŠŸèƒ½æ­£å¸¸
- [ ] è®¡åˆ’å¡ç‰‡æ˜¾ç¤ºæ—¶æœºæ­£ç¡®
- [ ] åŠ è½½åŠ¨ç”»æ˜¾ç¤ºæ—¶æœºæ­£ç¡®

### å†…å®¹æ¸²æŸ“
- [ ] æ¨ç†å†…å®¹æ­£ç¡®æµå¼æ›´æ–°
- [ ] Markdown æ ¼å¼æ­£ç¡®æ¸²æŸ“
- [ ] ä¸­æ–‡å†…å®¹æ­£ç¡®æ˜¾ç¤º
- [ ] å†…å®¹ä¸ä¸¢å¤±æˆ–é‡å¤

### æ€§èƒ½è¡¨ç°
- [ ] åŠ¨ç”»æµç•…ï¼Œæ— å¡é¡¿
- [ ] å†…å­˜ä½¿ç”¨æ­£å¸¸
- [ ] ç»„ä»¶é‡æ–°æ¸²æŸ“æ¬¡æ•°åˆç†

## æ•…éšœæ’é™¤

### æ€è€ƒå—ä¸è‡ªåŠ¨æŠ˜å 
1. æ£€æŸ¥ `hasMainContent` é€»è¾‘
2. éªŒè¯ `useEffect` ä¾èµ–é¡¹
3. ç¡®è®¤ `hasAutoCollapsed` çŠ¶æ€ç®¡ç†

### è®¡åˆ’å¡ç‰‡æ˜¾ç¤ºæ—¶æœºé”™è¯¯
1. æ£€æŸ¥ `shouldShowPlan` è®¡ç®—é€»è¾‘
2. éªŒè¯ `isThinking` çŠ¶æ€åˆ¤æ–­
3. ç¡®è®¤æ¶ˆæ¯å†…å®¹è§£ææ­£ç¡®

### ä¸»é¢˜åˆ‡æ¢å¼‚å¸¸
1. æ£€æŸ¥ `isStreaming` çŠ¶æ€
2. éªŒè¯ CSS ç±»ååº”ç”¨
3. ç¡®è®¤æ¡ä»¶æ¸²æŸ“é€»è¾‘


# æµå¼è¾“å‡ºä¼˜åŒ–æ”¹è¿›

## ğŸ¯ æ”¹è¿›ç›®æ ‡

ç¡®ä¿åœ¨æ·±åº¦æ€è€ƒç»“æŸåï¼Œplan block ä¿æŒæµå¼è¾“å‡ºæ•ˆæœï¼Œæä¾›æ›´æµç•…ä¸æ»‘çš„ç”¨æˆ·ä½“éªŒã€‚

## ğŸ”§ æŠ€æœ¯æ”¹è¿›

### çŠ¶æ€é€»è¾‘ä¼˜åŒ–

**ä¹‹å‰çš„é€»è¾‘**:
```typescript
const isThinking = reasoningContent && (!hasMainContent || message.isStreaming);
const shouldShowPlan = hasMainContent && !isThinking;
```

**ä¼˜åŒ–åçš„é€»è¾‘**:
```typescript
const isThinking = reasoningContent && !hasMainContent;
const shouldShowPlan = hasMainContent; // ç®€åŒ–é€»è¾‘ï¼Œæœ‰å†…å®¹å°±æ˜¾ç¤º
```

### å…³é”®æ”¹è¿›ç‚¹

1. **ç®€åŒ–æ˜¾ç¤ºé€»è¾‘**: åªè¦æœ‰ä¸»è¦å†…å®¹å°±æ˜¾ç¤º planï¼Œä¸å†ä¾èµ–æ€è€ƒçŠ¶æ€
2. **ä¿æŒæµå¼çŠ¶æ€**: plan ç»„ä»¶çš„ `animated` å±æ€§ç›´æ¥ä½¿ç”¨ `message.isStreaming`
3. **ä¼˜é›…å…¥åœºåŠ¨ç”»**: æ·»åŠ  motion.div åŒ…è£…ï¼Œæä¾›å¹³æ»‘çš„å‡ºç°æ•ˆæœ

## ğŸ¨ ç”¨æˆ·ä½“éªŒæå‡

### æµå¼è¾“å‡ºæ•ˆæœ

#### æ€è€ƒé˜¶æ®µ
- âœ… æ¨ç†å†…å®¹å®æ—¶æµå¼æ›´æ–°
- âœ… æ€è€ƒå—ä¿æŒå±•å¼€çŠ¶æ€
- âœ… Primary ä¸»é¢˜è‰²é«˜äº®æ˜¾ç¤º

#### è®¡åˆ’é˜¶æ®µ
- âœ… è®¡åˆ’å¡ç‰‡ä¼˜é›…å‡ºç°ï¼ˆ300ms åŠ¨ç”»ï¼‰
- âœ… æ ‡é¢˜å†…å®¹æµå¼æ¸²æŸ“
- âœ… æ€è·¯å†…å®¹æµå¼æ›´æ–°
- âœ… æ­¥éª¤åˆ—è¡¨é€é¡¹æ˜¾ç¤º
- âœ… æ¯ä¸ªæ­¥éª¤çš„æ ‡é¢˜å’Œæè¿°åˆ†åˆ«æµå¼æ¸²æŸ“

### åŠ¨ç”»æ•ˆæœ

#### è®¡åˆ’å¡ç‰‡å…¥åœºåŠ¨ç”»
```typescript
<motion.div
  initial={{ opacity: 0, y: 20 }}
  animate={{ opacity: 1, y: 0 }}
  transition={{ duration: 0.3, ease: "easeOut" }}
>
```

#### æµå¼æ–‡æœ¬åŠ¨ç”»
- æ‰€æœ‰ Markdown ç»„ä»¶éƒ½ä½¿ç”¨ `animated={message.isStreaming}`
- ç¡®ä¿æ–‡æœ¬é€å­—ç¬¦æˆ–é€è¯æ˜¾ç¤ºæ•ˆæœ

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### æ¸²æŸ“ä¼˜åŒ–
- **å‡å°‘é‡æ–°æ¸²æŸ“**: ç®€åŒ–çŠ¶æ€é€»è¾‘ï¼Œå‡å°‘ä¸å¿…è¦çš„ç»„ä»¶é‡æ–°æŒ‚è½½
- **ä¿æŒç»„ä»¶å®ä¾‹**: plan ç»„ä»¶ä¸€æ—¦å‡ºç°å°±ä¿æŒå­˜åœ¨ï¼Œé¿å…é‡æ–°åˆ›å»º
- **æµå¼çŠ¶æ€ä¼ é€’**: ç›´æ¥ä½¿ç”¨æ¶ˆæ¯çš„æµå¼çŠ¶æ€ï¼Œé¿å…é¢å¤–çš„çŠ¶æ€è®¡ç®—

### å†…å­˜ä¼˜åŒ–
- **ç»„ä»¶å¤ç”¨**: é¿å…é¢‘ç¹çš„ç»„ä»¶é”€æ¯å’Œé‡å»º
- **çŠ¶æ€ç®¡ç†**: ç®€åŒ–çŠ¶æ€ä¾èµ–ï¼Œå‡å°‘å†…å­˜å ç”¨

## ğŸ§ª æµ‹è¯•éªŒè¯

### æµå¼æ•ˆæœéªŒè¯
1. **æ€è€ƒé˜¶æ®µ**: æ¨ç†å†…å®¹åº”è¯¥é€æ­¥æ˜¾ç¤º
2. **è¿‡æ¸¡é˜¶æ®µ**: è®¡åˆ’å¡ç‰‡åº”è¯¥å¹³æ»‘å‡ºç°
3. **è®¡åˆ’é˜¶æ®µ**: æ‰€æœ‰è®¡åˆ’å†…å®¹åº”è¯¥ä¿æŒæµå¼æ•ˆæœ

### åŠ¨ç”»æ•ˆæœéªŒè¯
1. **å…¥åœºåŠ¨ç”»**: è®¡åˆ’å¡ç‰‡åº”è¯¥ä»ä¸‹æ–¹æ»‘å…¥å¹¶æ·¡å…¥
2. **æ–‡æœ¬åŠ¨ç”»**: æ‰€æœ‰æ–‡æœ¬å†…å®¹åº”è¯¥æœ‰æ‰“å­—æœºæ•ˆæœ
3. **çŠ¶æ€åˆ‡æ¢**: æ€è€ƒå—æŠ˜å åº”è¯¥å¹³æ»‘è‡ªç„¶

### æ€§èƒ½éªŒè¯
1. **æ¸²æŸ“æ¬¡æ•°**: æ£€æŸ¥ç»„ä»¶é‡æ–°æ¸²æŸ“é¢‘ç‡
2. **å†…å­˜ä½¿ç”¨**: ç›‘æ§å†…å­˜å ç”¨æƒ…å†µ
3. **åŠ¨ç”»æµç•…åº¦**: ç¡®ä¿ 60fps çš„åŠ¨ç”»æ•ˆæœ

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´äº¤äº’æµç¨‹
```
1. ç”¨æˆ·å‘é€é—®é¢˜ (å¯ç”¨æ·±åº¦æ€è€ƒ)
   â†“
2. æ€è€ƒå—å±•å¼€ï¼Œæ¨ç†å†…å®¹æµå¼æ˜¾ç¤º
   â†“
3. å¼€å§‹æ¥æ”¶è®¡åˆ’å†…å®¹
   â†“
4. æ€è€ƒå—è‡ªåŠ¨æŠ˜å 
   â†“
5. è®¡åˆ’å¡ç‰‡ä¼˜é›…å‡ºç° (åŠ¨ç”»æ•ˆæœ)
   â†“
6. è®¡åˆ’å†…å®¹æµå¼æ¸²æŸ“:
   - æ ‡é¢˜é€æ­¥æ˜¾ç¤º
   - æ€è·¯å†…å®¹æµå¼æ›´æ–°
   - æ­¥éª¤åˆ—è¡¨é€é¡¹æ˜¾ç¤º
   â†“
7. å®Œæˆï¼Œç”¨æˆ·å¯æŸ¥çœ‹å®Œæ•´å†…å®¹
```

## ğŸ”„ å…¼å®¹æ€§

- âœ… **å‘åå…¼å®¹**: ä¸å½±å“ç°æœ‰çš„éæ·±åº¦æ€è€ƒæ¨¡å¼
- âœ… **æ¸è¿›å¢å¼º**: åŠŸèƒ½ä»…åœ¨æœ‰æ¨ç†å†…å®¹æ—¶æ¿€æ´»
- âœ… **ä¼˜é›…é™çº§**: åœ¨ä¸æ”¯æŒçš„ç¯å¢ƒä¸­æ­£å¸¸æ˜¾ç¤º

## ğŸš€ æ•ˆæœæ€»ç»“

è¿™æ¬¡ä¼˜åŒ–æ˜¾è‘—æå‡äº†ç”¨æˆ·ä½“éªŒï¼š

1. **æ›´æµç•…çš„è¿‡æ¸¡**: ä»æ€è€ƒåˆ°è®¡åˆ’çš„åˆ‡æ¢æ›´åŠ è‡ªç„¶
2. **ä¿æŒæµå¼æ•ˆæœ**: è®¡åˆ’å†…å®¹ä¿æŒäº†åŸæœ‰çš„æµå¼è¾“å‡ºç‰¹æ€§
3. **è§†è§‰è¿è´¯æ€§**: æ•´ä¸ªè¿‡ç¨‹çš„è§†è§‰æ•ˆæœæ›´åŠ è¿è´¯ç»Ÿä¸€
4. **æ€§èƒ½æå‡**: å‡å°‘äº†ä¸å¿…è¦çš„ç»„ä»¶é‡æ–°æ¸²æŸ“

ç”¨æˆ·ç°åœ¨å¯ä»¥äº«å—åˆ°å®Œæ•´çš„æµå¼ä½“éªŒï¼Œä»æ·±åº¦æ€è€ƒåˆ°è®¡åˆ’å±•ç¤ºéƒ½ä¿æŒäº†ä¸€è‡´çš„æµç•…æ„Ÿã€‚

# æµ‹è¯•æ€è€ƒå—åŠŸèƒ½

## å¿«é€Ÿæµ‹è¯•

### æ–¹æ³• 1: ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®

1. åœ¨æµè§ˆå™¨ä¸­è®¿é—®åº”ç”¨å¹¶æ·»åŠ  `?mock=reasoning-example` å‚æ•°
2. å‘é€ä»»æ„æ¶ˆæ¯
3. è§‚å¯Ÿè®¡åˆ’å¡ç‰‡ä¸Šæ–¹æ˜¯å¦å‡ºç°æ€è€ƒå—

### æ–¹æ³• 2: å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼

1. ç¡®ä¿é…ç½®äº† reasoning æ¨¡å‹ï¼ˆå¦‚ DeepSeek R1ï¼‰
2. åœ¨èŠå¤©ç•Œé¢ç‚¹å‡»"Deep Thinking"æŒ‰é’®
3. å‘é€ä¸€ä¸ªéœ€è¦è§„åˆ’çš„é—®é¢˜
4. è§‚å¯Ÿæ˜¯å¦å‡ºç°æ€è€ƒå—

## é¢„æœŸè¡Œä¸º

### æ€è€ƒå—å¤–è§‚
- æ·±åº¦æ€è€ƒå¼€å§‹æ—¶è‡ªåŠ¨å±•å¼€æ˜¾ç¤º
- æ€è€ƒé˜¶æ®µä½¿ç”¨ primary ä¸»é¢˜è‰²ï¼ˆè¾¹æ¡†ã€èƒŒæ™¯ã€æ–‡å­—ã€å›¾æ ‡ï¼‰
- å¸¦æœ‰ 18px å¤§è„‘å›¾æ ‡å’Œ"æ·±åº¦æ€è€ƒè¿‡ç¨‹"æ ‡é¢˜
- ä½¿ç”¨ `font-semibold` å­—ä½“æƒé‡ï¼Œä¸ CardTitle ä¿æŒä¸€è‡´
- `rounded-xl` åœ†è§’è®¾è®¡ï¼Œä¸å…¶ä»–å¡ç‰‡ç»„ä»¶ç»Ÿä¸€
- æ ‡å‡†çš„ `px-6 py-4` å†…è¾¹è·

### äº¤äº’è¡Œä¸º
- æ€è€ƒé˜¶æ®µï¼šè‡ªåŠ¨å±•å¼€ï¼Œè“è‰²é«˜äº®ï¼Œæ˜¾ç¤ºåŠ è½½åŠ¨ç”»
- è®¡åˆ’é˜¶æ®µï¼šè‡ªåŠ¨æŠ˜å ï¼Œåˆ‡æ¢ä¸ºé»˜è®¤ä¸»é¢˜
- ç”¨æˆ·å¯éšæ—¶æ‰‹åŠ¨å±•å¼€/æŠ˜å 
- å¹³æ»‘çš„å±•å¼€/æŠ˜å åŠ¨ç”»å’Œä¸»é¢˜åˆ‡æ¢

### åˆ†é˜¶æ®µæ˜¾ç¤º
- æ€è€ƒé˜¶æ®µï¼šåªæ˜¾ç¤ºæ€è€ƒå—ï¼Œä¸æ˜¾ç¤ºè®¡åˆ’å¡ç‰‡
- è®¡åˆ’é˜¶æ®µï¼šæ€è€ƒå—æŠ˜å ï¼Œæ˜¾ç¤ºå®Œæ•´è®¡åˆ’å¡ç‰‡

### å†…å®¹æ¸²æŸ“
- æ”¯æŒ Markdown æ ¼å¼
- ä¸­æ–‡å†…å®¹æ­£ç¡®æ˜¾ç¤º
- ä¿æŒåŸæœ‰çš„æ¢è¡Œå’Œæ ¼å¼

## æ•…éšœæ’é™¤

### æ€è€ƒå—ä¸æ˜¾ç¤º
1. æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦åŒ…å« `reasoningContent` å­—æ®µ
2. ç¡®è®¤ `reasoning_content` äº‹ä»¶æ˜¯å¦æ­£ç¡®å¤„ç†
3. éªŒè¯æ¶ˆæ¯åˆå¹¶é€»è¾‘æ˜¯å¦æ­£å¸¸å·¥ä½œ

### å†…å®¹æ˜¾ç¤ºå¼‚å¸¸
1. æ£€æŸ¥ Markdown æ¸²æŸ“æ˜¯å¦æ­£å¸¸
2. ç¡®è®¤ CSS æ ·å¼æ˜¯å¦æ­£ç¡®åŠ è½½
3. éªŒè¯åŠ¨ç”»æ•ˆæœæ˜¯å¦å¯ç”¨

### æµå¼ä¼ è¾“é—®é¢˜
1. æ£€æŸ¥ WebSocket è¿æ¥çŠ¶æ€
2. ç¡®è®¤äº‹ä»¶æµæ ¼å¼æ˜¯å¦æ­£ç¡®
3. éªŒè¯æ¶ˆæ¯æ›´æ–°é€»è¾‘

## å¼€å‘è°ƒè¯•

### æ§åˆ¶å°æ£€æŸ¥
```javascript
// æ£€æŸ¥æ¶ˆæ¯å¯¹è±¡
const messages = useStore.getState().messages;
const lastMessage = Array.from(messages.values()).pop();
console.log('Reasoning content:', lastMessage?.reasoningContent);
```

### ç½‘ç»œé¢æ¿
- æŸ¥çœ‹ SSE äº‹ä»¶æµ
- ç¡®è®¤ `reasoning_content` å­—æ®µå­˜åœ¨
- æ£€æŸ¥äº‹ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®

### React DevTools
- æ£€æŸ¥ ThoughtBlock ç»„ä»¶çŠ¶æ€
- éªŒè¯ props ä¼ é€’æ˜¯å¦æ­£ç¡®
- è§‚å¯Ÿç»„ä»¶é‡æ–°æ¸²æŸ“æƒ…å†µ

# æ€è€ƒå—è®¾è®¡ç³»ç»Ÿè§„èŒƒ

## ğŸ¯ è®¾è®¡ç›®æ ‡

ç¡®ä¿æ€è€ƒå—ç»„ä»¶ä¸æ•´ä¸ªåº”ç”¨çš„è®¾è®¡è¯­è¨€ä¿æŒå®Œå…¨ä¸€è‡´ï¼Œæä¾›ç»Ÿä¸€çš„ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“ è®¾è®¡è§„èŒƒ

### å­—ä½“ç³»ç»Ÿ
```css
/* æ ‡é¢˜å­—ä½“ - ä¸ CardTitle ä¿æŒä¸€è‡´ */
font-weight: 600; /* font-semibold */
line-height: 1; /* leading-none */
```

### å°ºå¯¸è§„èŒƒ
```css
/* å›¾æ ‡å°ºå¯¸ */
icon-size: 18px; /* ä¸æ–‡å­—æ¯”ä¾‹åè°ƒ */

/* å†…è¾¹è· */
padding: 1.5rem; /* px-6 py-4 */

/* å¤–è¾¹è· */
margin-bottom: 1.5rem; /* mb-6 */

/* åœ†è§’ */
border-radius: 0.75rem; /* rounded-xl */
```

### é¢œè‰²ç³»ç»Ÿ

#### æ€è€ƒé˜¶æ®µï¼ˆæ´»è·ƒçŠ¶æ€ï¼‰
```css
/* è¾¹æ¡†å’ŒèƒŒæ™¯ */
border-color: hsl(var(--primary) / 0.2);
background-color: hsl(var(--primary) / 0.05);

/* å›¾æ ‡å’Œæ–‡å­— */
color: hsl(var(--primary));

/* é˜´å½± */
box-shadow: 0 1px 2px 0 rgb(0 0 0 / 0.05);
```

#### å®Œæˆé˜¶æ®µï¼ˆé™æ€çŠ¶æ€ï¼‰
```css
/* è¾¹æ¡†å’ŒèƒŒæ™¯ */
border-color: hsl(var(--border));
background-color: hsl(var(--card));

/* å›¾æ ‡ */
color: hsl(var(--muted-foreground));

/* æ–‡å­— */
color: hsl(var(--foreground));
```

#### å†…å®¹åŒºåŸŸ
```css
/* æ€è€ƒé˜¶æ®µ */
.prose-primary {
  color: hsl(var(--primary));
}

/* å®Œæˆé˜¶æ®µ */
.opacity-80 {
  opacity: 0.8;
}
```

### äº¤äº’çŠ¶æ€
```css
/* æ‚¬åœçŠ¶æ€ */
.hover\:bg-accent:hover {
  background-color: hsl(var(--accent));
}

.hover\:text-accent-foreground:hover {
  color: hsl(var(--accent-foreground));
}
```

## ğŸ”„ çŠ¶æ€å˜åŒ–

### çŠ¶æ€æ˜ å°„
| çŠ¶æ€ | è¾¹æ¡† | èƒŒæ™¯ | å›¾æ ‡é¢œè‰² | æ–‡å­—é¢œè‰² | é˜´å½± |
|------|------|------|----------|----------|------|
| æ€è€ƒä¸­ | primary/20 | primary/5 | primary | primary | æœ‰ |
| å·²å®Œæˆ | border | card | muted-foreground | foreground | æ—  |

### åŠ¨ç”»è¿‡æ¸¡
```css
transition: all 200ms ease-in-out;
```

## ğŸ“± å“åº”å¼è®¾è®¡

### é—´è·é€‚é…
- ç§»åŠ¨ç«¯ï¼šä¿æŒç›¸åŒçš„å†…è¾¹è·æ¯”ä¾‹
- æ¡Œé¢ç«¯ï¼šæ ‡å‡†çš„ `px-6 py-4` å†…è¾¹è·

### å­—ä½“é€‚é…
- æ‰€æœ‰è®¾å¤‡ï¼šä¿æŒ `font-semibold` å­—ä½“æƒé‡
- å›¾æ ‡å°ºå¯¸ï¼šå›ºå®š 18pxï¼Œç¡®ä¿æ¸…æ™°åº¦

## ğŸ¨ ä¸ç°æœ‰ç»„ä»¶çš„å¯¹æ¯”

### CardTitle å¯¹æ¯”
| å±æ€§ | CardTitle | ThoughtBlock |
|------|-----------|--------------|
| å­—ä½“æƒé‡ | font-semibold | font-semibold âœ… |
| è¡Œé«˜ | leading-none | leading-none âœ… |
| é¢œè‰² | foreground | primary/foreground |

### Card å¯¹æ¯”
| å±æ€§ | Card | ThoughtBlock |
|------|------|--------------|
| åœ†è§’ | rounded-lg | rounded-xl |
| è¾¹æ¡† | border | border âœ… |
| èƒŒæ™¯ | card | card/primary âœ… |

### Button å¯¹æ¯”
| å±æ€§ | Button | ThoughtBlock Trigger |
|------|--------|---------------------|
| å†…è¾¹è· | æ ‡å‡† | px-6 py-4 âœ… |
| æ‚¬åœ | hover:bg-accent | hover:bg-accent âœ… |
| åœ†è§’ | rounded-md | rounded-xl |

## âœ… è®¾è®¡æ£€æŸ¥æ¸…å•

### è§†è§‰ä¸€è‡´æ€§
- [ ] å­—ä½“æƒé‡ä¸ CardTitle ä¸€è‡´
- [ ] åœ†è§’è®¾è®¡ä¸å¡ç‰‡ç»„ä»¶ç»Ÿä¸€
- [ ] é¢œè‰²ä½¿ç”¨ CSS å˜é‡ç³»ç»Ÿ
- [ ] é—´è·ç¬¦åˆè®¾è®¡è§„èŒƒ

### äº¤äº’ä¸€è‡´æ€§
- [ ] æ‚¬åœçŠ¶æ€ä¸ Button ç»„ä»¶ä¸€è‡´
- [ ] è¿‡æ¸¡åŠ¨ç”»æ—¶é•¿ç»Ÿä¸€ï¼ˆ200msï¼‰
- [ ] çŠ¶æ€å˜åŒ–å¹³æ»‘è‡ªç„¶

### å¯è®¿é—®æ€§
- [ ] é¢œè‰²å¯¹æ¯”åº¦ç¬¦åˆ WCAG æ ‡å‡†
- [ ] å›¾æ ‡å°ºå¯¸é€‚åˆç‚¹å‡»/è§¦æ‘¸
- [ ] çŠ¶æ€å˜åŒ–æœ‰æ˜ç¡®çš„è§†è§‰åé¦ˆ

## ğŸ”§ å®ç°è¦ç‚¹

1. **ä½¿ç”¨è®¾è®¡ç³»ç»Ÿå˜é‡**: æ‰€æœ‰é¢œè‰²éƒ½ä½¿ç”¨ CSS å˜é‡ï¼Œç¡®ä¿ä¸»é¢˜åˆ‡æ¢æ­£å¸¸
2. **ä¿æŒç»„ä»¶ä¸€è‡´æ€§**: ä¸ç°æœ‰ Cardã€Button ç»„ä»¶çš„æ ·å¼ä¿æŒä¸€è‡´
3. **å“åº”å¼å‹å¥½**: åœ¨ä¸åŒè®¾å¤‡ä¸Šéƒ½æœ‰è‰¯å¥½çš„æ˜¾ç¤ºæ•ˆæœ
4. **æ€§èƒ½ä¼˜åŒ–**: ä½¿ç”¨ CSS è¿‡æ¸¡è€Œé JavaScript åŠ¨ç”»

è¿™ä¸ªè®¾è®¡ç³»ç»Ÿç¡®ä¿äº†æ€è€ƒå—ç»„ä»¶ä¸æ•´ä¸ªåº”ç”¨çš„è§†è§‰è¯­è¨€å®Œå…¨ç»Ÿä¸€ï¼Œæä¾›äº†ä¸€è‡´çš„ç”¨æˆ·ä½“éªŒã€‚


# æ€è€ƒå—åŠŸèƒ½ (Thought Block Feature)

## æ¦‚è¿°

æ€è€ƒå—åŠŸèƒ½å…è®¸åœ¨è®¡åˆ’å¡ç‰‡ä¹‹å‰å±•ç¤º AI çš„æ·±åº¦æ€è€ƒè¿‡ç¨‹ï¼Œä»¥å¯æŠ˜å çš„æ–¹å¼å‘ˆç°æ¨ç†å†…å®¹ã€‚è¿™ä¸ªåŠŸèƒ½ç‰¹åˆ«é€‚ç”¨äºå¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼æ—¶çš„åœºæ™¯ã€‚

## åŠŸèƒ½ç‰¹æ€§

- **æ™ºèƒ½å±•ç¤ºé€»è¾‘**: æ·±åº¦æ€è€ƒè¿‡ç¨‹åˆå§‹å±•å¼€ï¼Œå½“å¼€å§‹æ¥æ”¶è®¡åˆ’å†…å®¹æ—¶è‡ªåŠ¨æŠ˜å 
- **åˆ†é˜¶æ®µæ˜¾ç¤º**: æ€è€ƒé˜¶æ®µåªæ˜¾ç¤ºæ€è€ƒå—ï¼Œæ€è€ƒç»“æŸåæ‰æ˜¾ç¤ºè®¡åˆ’å¡ç‰‡
- **æµå¼æ”¯æŒ**: æ”¯æŒæ¨ç†å†…å®¹çš„å®æ—¶æµå¼å±•ç¤º
- **è§†è§‰çŠ¶æ€åé¦ˆ**: æ€è€ƒé˜¶æ®µä½¿ç”¨è“è‰²ä¸»é¢˜çªå‡ºæ˜¾ç¤º
- **ä¼˜é›…çš„åŠ¨ç”»**: åŒ…å«å¹³æ»‘çš„å±•å¼€/æŠ˜å åŠ¨ç”»æ•ˆæœ
- **å“åº”å¼è®¾è®¡**: é€‚é…ä¸åŒå±å¹•å°ºå¯¸

## æŠ€æœ¯å®ç°

### æ•°æ®ç»“æ„æ›´æ–°

1. **Message ç±»å‹æ‰©å±•**:
   ```typescript
   export interface Message {
     // ... å…¶ä»–å­—æ®µ
     reasoningContent?: string;
     reasoningContentChunks?: string[];
   }
   ```

2. **API äº‹ä»¶ç±»å‹æ‰©å±•**:
   ```typescript
   export interface MessageChunkEvent {
     // ... å…¶ä»–å­—æ®µ
     reasoning_content?: string;
   }
   ```

### ç»„ä»¶ç»“æ„

- **ThoughtBlock**: ä¸»è¦çš„æ€è€ƒå—ç»„ä»¶
  - ä½¿ç”¨ Radix UI çš„ Collapsible ç»„ä»¶
  - æ”¯æŒæµå¼å†…å®¹å±•ç¤º
  - åŒ…å«åŠ è½½åŠ¨ç”»å’ŒçŠ¶æ€æŒ‡ç¤º

- **PlanCard**: æ›´æ–°åçš„è®¡åˆ’å¡ç‰‡
  - åœ¨è®¡åˆ’å†…å®¹ä¹‹å‰å±•ç¤ºæ€è€ƒå—
  - è‡ªåŠ¨æ£€æµ‹æ˜¯å¦æœ‰æ¨ç†å†…å®¹

### æ¶ˆæ¯å¤„ç†

æ¶ˆæ¯åˆå¹¶é€»è¾‘å·²æ›´æ–°ä»¥æ”¯æŒ `reasoning_content` å­—æ®µçš„æµå¼å¤„ç†ï¼š

```typescript
function mergeTextMessage(message: Message, event: MessageChunkEvent) {
  // å¤„ç†å¸¸è§„å†…å®¹
  if (event.data.content) {
    message.content += event.data.content;
    message.contentChunks.push(event.data.content);
  }
  
  // å¤„ç†æ¨ç†å†…å®¹
  if (event.data.reasoning_content) {
    message.reasoningContent = (message.reasoningContent || "") + event.data.reasoning_content;
    message.reasoningContentChunks = message.reasoningContentChunks || [];
    message.reasoningContentChunks.push(event.data.reasoning_content);
  }
}
```

## ä½¿ç”¨æ–¹æ³•

### å¯ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼

1. åœ¨èŠå¤©ç•Œé¢ä¸­ï¼Œç‚¹å‡»"Deep Thinking"æŒ‰é’®
2. ç¡®ä¿é…ç½®äº†æ”¯æŒæ¨ç†çš„æ¨¡å‹
3. å‘é€æ¶ˆæ¯åï¼Œå¦‚æœæœ‰æ¨ç†å†…å®¹ï¼Œä¼šåœ¨è®¡åˆ’å¡ç‰‡ä¸Šæ–¹æ˜¾ç¤ºæ€è€ƒå—

### æŸ¥çœ‹æ¨ç†è¿‡ç¨‹

1. æ·±åº¦æ€è€ƒå¼€å§‹æ—¶ï¼Œæ€è€ƒå—è‡ªåŠ¨å±•å¼€æ˜¾ç¤º
2. æ€è€ƒé˜¶æ®µä½¿ç”¨ primary ä¸»é¢˜è‰²ï¼Œçªå‡ºæ˜¾ç¤ºæ­£åœ¨è¿›è¡Œçš„æ¨ç†è¿‡ç¨‹
3. æ¨ç†å†…å®¹æ”¯æŒ Markdown æ ¼å¼æ¸²æŸ“ï¼Œå®æ—¶æµå¼æ›´æ–°
4. åœ¨æµå¼ä¼ è¾“è¿‡ç¨‹ä¸­ä¼šæ˜¾ç¤ºåŠ è½½åŠ¨ç”»
5. å½“å¼€å§‹æ¥æ”¶è®¡åˆ’å†…å®¹æ—¶ï¼Œæ€è€ƒå—è‡ªåŠ¨æŠ˜å 
6. è®¡åˆ’å¡ç‰‡ä»¥ä¼˜é›…çš„åŠ¨ç”»æ•ˆæœå‡ºç°
7. è®¡åˆ’å†…å®¹ä¿æŒæµå¼è¾“å‡ºæ•ˆæœï¼Œé€æ­¥æ˜¾ç¤ºæ ‡é¢˜ã€æ€è·¯å’Œæ­¥éª¤
8. ç”¨æˆ·å¯ä»¥éšæ—¶ç‚¹å‡»æ€è€ƒå—æ ‡é¢˜æ æ‰‹åŠ¨å±•å¼€/æŠ˜å 

## æ ·å¼ç‰¹æ€§

- **ç»Ÿä¸€è®¾è®¡è¯­è¨€**: ä¸é¡µé¢æ•´ä½“è®¾è®¡é£æ ¼ä¿æŒä¸€è‡´
- **å­—ä½“å±‚æ¬¡**: ä½¿ç”¨ä¸ CardTitle ç›¸åŒçš„ `font-semibold` å­—ä½“æƒé‡
- **åœ†è§’è®¾è®¡**: é‡‡ç”¨ `rounded-xl` ä¸å…¶ä»–å¡ç‰‡ç»„ä»¶ä¿æŒä¸€è‡´
- **é—´è·è§„èŒƒ**: ä½¿ç”¨æ ‡å‡†çš„ `px-6 py-4` å†…è¾¹è·
- **åŠ¨æ€ä¸»é¢˜**: æ€è€ƒé˜¶æ®µä½¿ç”¨ primary è‰²å½©ç³»ç»Ÿ
- **å›¾æ ‡å°ºå¯¸**: 18px å›¾æ ‡å°ºå¯¸ï¼Œä¸æ–‡å­—æ¯”ä¾‹åè°ƒ
- **çŠ¶æ€åé¦ˆ**: æµå¼ä¼ è¾“æ—¶æ˜¾ç¤ºåŠ è½½åŠ¨ç”»å’Œä¸»é¢˜è‰²é«˜äº®
- **äº¤äº’åé¦ˆ**: æ ‡å‡†çš„ hover å’Œ focus çŠ¶æ€
- **å¹³æ»‘è¿‡æ¸¡**: æ‰€æœ‰çŠ¶æ€å˜åŒ–éƒ½æœ‰å¹³æ»‘çš„è¿‡æ¸¡åŠ¨ç”»

## æµ‹è¯•æ•°æ®

å¯ä»¥ä½¿ç”¨ `/mock/reasoning-example.txt` æ–‡ä»¶æµ‹è¯•æ€è€ƒå—åŠŸèƒ½ï¼Œè¯¥æ–‡ä»¶åŒ…å«äº†æ¨¡æ‹Ÿçš„æ¨ç†å†…å®¹å’Œè®¡åˆ’æ•°æ®ã€‚

## å…¼å®¹æ€§

- å‘åå…¼å®¹ï¼šæ²¡æœ‰æ¨ç†å†…å®¹çš„æ¶ˆæ¯ä¸ä¼šæ˜¾ç¤ºæ€è€ƒå—
- æ¸è¿›å¢å¼ºï¼šåŠŸèƒ½ä»…åœ¨æœ‰æ¨ç†å†…å®¹æ—¶æ¿€æ´»
- ä¼˜é›…é™çº§ï¼šå¦‚æœæ¨ç†å†…å®¹ä¸ºç©ºï¼Œç»„ä»¶ä¸ä¼šæ¸²æŸ“




